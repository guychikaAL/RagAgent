{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ“š Summary Agent - Testing\n",
        "\n",
        "This notebook tests the **Summary Agent** for contextual synthesis.\n",
        "\n",
        "## What is Tested\n",
        "\n",
        "- âœ… Contextual synthesis from multiple chunks\n",
        "- âœ… Coherent explanation generation\n",
        "- âœ… Handling questions with partial context\n",
        "- âœ… Confidence scoring based on coverage\n",
        "- âœ… Source traceability\n",
        "\n",
        "## Test Strategy\n",
        "\n",
        "**Mock Retriever Approach:**\n",
        "- Uses a mock retriever that returns merged parent chunks\n",
        "- No FAISS, no embeddings, no index building\n",
        "- Self-contained and reproducible\n",
        "- Tests only the synthesis logic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ“¦ Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Project root: /Users/guyai/Desktop/AI Lecture/FIRST PROJECT/RagAgentv2\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "from dataclasses import dataclass\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path.cwd().parent.parent\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "print(f\"âœ… Project root: {project_root}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Environment loaded\n",
            "   OpenAI API Key: ********************NQQA\n"
          ]
        }
      ],
      "source": [
        "# Load environment\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "env_path = project_root / \".env\"\n",
        "load_dotenv(env_path)\n",
        "\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"OPENAI_API_KEY not found in .env file\")\n",
        "\n",
        "print(\"âœ… Environment loaded\")\n",
        "print(f\"   OpenAI API Key: {'*' * 20}{api_key[-4:]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ”§ Mock Summary Retriever\n",
        "\n",
        "Since we're testing ONLY the synthesis logic (not retrieval), we create a **mock retriever** that returns contextual chunks simulating Auto-Merging.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Mock summary retriever created\n",
            "   Knowledge base: 5 merged parent chunks\n"
          ]
        }
      ],
      "source": [
        "# Mock objects to simulate LlamaIndex retriever output\n",
        "\n",
        "@dataclass\n",
        "class MockNode:\n",
        "    \"\"\"Mock LlamaIndex Node.\"\"\"\n",
        "    node_id: str\n",
        "    text: str\n",
        "\n",
        "@dataclass\n",
        "class MockNodeWithScore:\n",
        "    \"\"\"Mock LlamaIndex NodeWithScore.\"\"\"\n",
        "    node: MockNode\n",
        "    score: float\n",
        "\n",
        "\n",
        "class MockSummaryRetriever:\n",
        "    \"\"\"\n",
        "    Mock summary retriever for testing Summary Agent.\n",
        "    \n",
        "    Simulates Auto-Merging retriever without needing FAISS or embeddings.\n",
        "    Returns merged parent chunks based on question keywords.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Simulate merged parent chunks about an insurance claim\n",
        "        # These chunks are LONGER and contain MORE CONTEXT than needle chunks\n",
        "        self.knowledge_base = {\n",
        "            \"incident_overview\": MockNodeWithScore(\n",
        "                node=MockNode(\n",
        "                    node_id=\"parent_001\",\n",
        "                    text=\"\"\"INCIDENT OVERVIEW:\n",
        "The accident occurred on January 15, 2024 at approximately 2:30 PM on Interstate 95, \n",
        "northbound lane near Exit 42. Weather conditions at the time included heavy rain with \n",
        "poor visibility (estimated 100 feet). Traffic was moving slowly due to weather.\n",
        "\n",
        "The incident involved two vehicles: a 2020 Honda Accord (claimant vehicle) and a \n",
        "2019 Toyota Camry (other party). The Honda Accord was traveling in the middle lane \n",
        "when traffic suddenly slowed. The vehicle attempted to brake but was unable to stop \n",
        "in time, resulting in a rear-end collision with the Toyota Camry ahead.\n",
        "\n",
        "No injuries were reported at the scene. Both drivers exchanged information and \n",
        "remained at the location until police arrived. Police report filed under case \n",
        "number PD-2024-1234.\"\"\"\n",
        "                ),\n",
        "                score=0.92\n",
        "            ),\n",
        "            \"vehicle_and_claimant\": MockNodeWithScore(\n",
        "                node=MockNode(\n",
        "                    node_id=\"parent_002\",\n",
        "                    text=\"\"\"CLAIMANT AND VEHICLE INFORMATION:\n",
        "Claimant: John Michael Doe, age 35\n",
        "Contact: Phone 555-123-4567, Address: 123 Main Street, Springfield, State 12345\n",
        "Email: john.doe@email.com\n",
        "\n",
        "Vehicle: 2020 Honda Accord, 4-door sedan, Silver\n",
        "VIN: 1HGCV1F30LA123456\n",
        "License Plate: ABC-1234\n",
        "Mileage at incident: 45,230 miles\n",
        "Registration: Current, registered to John Doe\n",
        "\n",
        "Insurance Policy: POL-556789\n",
        "Policy holder: John Doe\n",
        "Coverage: Full coverage including collision and comprehensive\n",
        "Deductible: $500\"\"\"\n",
        "                ),\n",
        "                score=0.89\n",
        "            ),\n",
        "            \"damage_assessment\": MockNodeWithScore(\n",
        "                node=MockNode(\n",
        "                    node_id=\"parent_003\",\n",
        "                    text=\"\"\"DAMAGE ASSESSMENT AND REPAIRS:\n",
        "Initial damage estimate: $4,500\n",
        "\n",
        "Damage description:\n",
        "- Front bumper: Significant damage, requires replacement\n",
        "- Hood: Minor dent, paintless dent repair recommended\n",
        "- Front grille: Cracked, requires replacement\n",
        "- Right headlight: Housing cracked, full replacement needed\n",
        "- Radiator: No visible damage, but inspection recommended\n",
        "\n",
        "Adjuster assigned: Sarah Johnson, assigned January 16, 2024\n",
        "Inspection completed: January 18, 2024\n",
        "Adjuster notes: Damage consistent with low-speed rear-end collision. \n",
        "No structural damage observed. Repairs can proceed.\n",
        "\n",
        "Approved repair shop: AutoFix Collision Center, 456 Repair Ave\n",
        "Estimated repair time: 5-7 business days\n",
        "Parts availability: All parts in stock\"\"\"\n",
        "                ),\n",
        "                score=0.91\n",
        "            ),\n",
        "            \"claim_processing\": MockNodeWithScore(\n",
        "                node=MockNode(\n",
        "                    node_id=\"parent_004\",\n",
        "                    text=\"\"\"CLAIM PROCESSING TIMELINE:\n",
        "Claim Number: CLM-2024-00789\n",
        "Filed: January 15, 2024, 6:45 PM (same day as incident)\n",
        "Initial review: January 16, 2024, 9:00 AM\n",
        "Status: Approved\n",
        "\n",
        "Processing timeline:\n",
        "- January 15: Claim filed online, confirmation email sent\n",
        "- January 16: Claim assigned to adjuster Sarah Johnson\n",
        "- January 16: Initial contact made with claimant\n",
        "- January 18: Vehicle inspection completed\n",
        "- January 18: Damage estimate approved\n",
        "- January 19: Repair authorization sent to AutoFix Collision Center\n",
        "- January 22: Repairs scheduled to begin\n",
        "\n",
        "Payment processing:\n",
        "- Total approved: $4,500\n",
        "- Deductible: $500\n",
        "- Amount paid to repair shop: $4,000\n",
        "- Payment method: Direct payment to shop\n",
        "- Expected completion: January 29, 2024\"\"\"\n",
        "                ),\n",
        "                score=0.90\n",
        "            ),\n",
        "            \"other_party\": MockNodeWithScore(\n",
        "                node=MockNode(\n",
        "                    node_id=\"parent_005\",\n",
        "                    text=\"\"\"OTHER PARTY INFORMATION:\n",
        "Driver: Jane Smith, age 42\n",
        "Vehicle: 2019 Toyota Camry, Blue\n",
        "License Plate: XYZ-9876\n",
        "\n",
        "Contact: Phone 555-987-6543\n",
        "\n",
        "Insurance: State Farm Insurance\n",
        "Policy reported: Yes\n",
        "Claim filed with their insurance: Yes\n",
        "\n",
        "Damage to other party vehicle:\n",
        "- Rear bumper: Minor damage, scratches and scuff marks\n",
        "- Trunk: No damage\n",
        "- Estimated repair cost: $800\n",
        "\n",
        "Other party statement: \"I was driving in my lane when I felt an impact from behind. \n",
        "Weather was bad with heavy rain. I don't blame the other driver - visibility was \n",
        "really poor.\"\n",
        "\n",
        "No injuries reported by other party.\n",
        "No dispute regarding fault.\"\"\"\n",
        "                ),\n",
        "                score=0.87\n",
        "            ),\n",
        "        }\n",
        "    \n",
        "    def retrieve(self, question: str) -> List[MockNodeWithScore]:\n",
        "        \"\"\"\n",
        "        Mock retrieval based on keywords in question.\n",
        "        \n",
        "        Simulates what a summary retriever would do:\n",
        "        - Match question to relevant merged chunks\n",
        "        - Return multiple contextual chunks\n",
        "        - No threshold (high recall for summary)\n",
        "        \"\"\"\n",
        "        question_lower = question.lower()\n",
        "        results = []\n",
        "        \n",
        "        # Keyword-based matching (simulates semantic search)\n",
        "        # Summary questions often match multiple chunks\n",
        "        \n",
        "        if any(word in question_lower for word in [\"incident\", \"accident\", \"happen\", \"occur\", \"describe\"]):\n",
        "            results.append(self.knowledge_base[\"incident_overview\"])\n",
        "        \n",
        "        if any(word in question_lower for word in [\"claimant\", \"driver\", \"vehicle\", \"car\", \"who\"]):\n",
        "            results.append(self.knowledge_base[\"vehicle_and_claimant\"])\n",
        "        \n",
        "        if any(word in question_lower for word in [\"damage\", \"repair\", \"estimate\", \"cost\", \"broken\"]):\n",
        "            results.append(self.knowledge_base[\"damage_assessment\"])\n",
        "        \n",
        "        if any(word in question_lower for word in [\"claim\", \"process\", \"timeline\", \"filed\", \"status\"]):\n",
        "            results.append(self.knowledge_base[\"claim_processing\"])\n",
        "        \n",
        "        if any(word in question_lower for word in [\"other party\", \"other driver\", \"toyota\", \"jane\"]):\n",
        "            results.append(self.knowledge_base[\"other_party\"])\n",
        "        \n",
        "        # For broad questions, return multiple chunks\n",
        "        if any(word in question_lower for word in [\"summary\", \"overview\", \"everything\", \"all\", \"complete\"]):\n",
        "            results = [\n",
        "                self.knowledge_base[\"incident_overview\"],\n",
        "                self.knowledge_base[\"vehicle_and_claimant\"],\n",
        "                self.knowledge_base[\"damage_assessment\"],\n",
        "                self.knowledge_base[\"claim_processing\"],\n",
        "            ]\n",
        "        \n",
        "        # Simulate \"minimal context\" for questions outside scope\n",
        "        if \"injury\" in question_lower or \"injuries\" in question_lower:\n",
        "            # Return incident chunk which mentions no injuries, but lacks detail\n",
        "            results.append(self.knowledge_base[\"incident_overview\"])\n",
        "        \n",
        "        return results\n",
        "\n",
        "\n",
        "# Create mock retriever\n",
        "mock_retriever = MockSummaryRetriever()\n",
        "print(\"âœ… Mock summary retriever created\")\n",
        "print(f\"   Knowledge base: {len(mock_retriever.knowledge_base)} merged parent chunks\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ¤– Initialize Summary Agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Summary Agent initialized\n",
            "   Model: gpt-4o-mini\n",
            "   Temperature: 0.2\n",
            "   Output: Structured (Pydantic)\n",
            "   Policy: CONTEXT-GROUNDED SYNTHESIS\n",
            "\n",
            "============================================================\n",
            "Summary Agent ready for testing!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "from RAG.Agents.summary_agent import SummaryAgent, create_summary_agent\n",
        "\n",
        "# Create agent\n",
        "agent = create_summary_agent(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0.2  # Slightly higher than needle for coherence\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Summary Agent ready for testing!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ§ª Test Suite\n",
        "\n",
        "We'll test 5+ summary-style questions covering:\n",
        "1. Overview questions (multiple chunks)\n",
        "2. Descriptive questions (narrative)\n",
        "3. Process questions (timeline/flow)\n",
        "4. Partial context (incomplete information)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function to display results\n",
        "def test_question(question: str, expected_confidence: str = \"high\"):\n",
        "    \"\"\"\n",
        "    Test a single question and display results.\n",
        "    \n",
        "    Args:\n",
        "        question: The summary question to test\n",
        "        expected_confidence: \"high\" (>0.7), \"medium\" (0.4-0.7), or \"low\" (â‰¤0.3)\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"â“ QUESTION: {question}\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Call agent\n",
        "    result = agent.answer(question, mock_retriever)\n",
        "    \n",
        "    # Display results\n",
        "    print(f\"\\nðŸ“ ANSWER:\")\n",
        "    print(f\"{result['answer']}\")\n",
        "    print(f\"\\nðŸŽ¯ CONFIDENCE:  {result['confidence']:.2f}\")\n",
        "    print(f\"ðŸ“š SOURCES:     {result['sources']}\")\n",
        "    print(f\"ðŸ’¡ REASON:      {result['reason']}\")\n",
        "    \n",
        "    # Validation\n",
        "    conf = result['confidence']\n",
        "    if expected_confidence == \"high\" and conf > 0.7:\n",
        "        print(\"\\nâœ… PASS - High confidence as expected\")\n",
        "    elif expected_confidence == \"medium\" and 0.4 <= conf <= 0.7:\n",
        "        print(\"\\nâœ… PASS - Medium confidence as expected\")\n",
        "    elif expected_confidence == \"low\" and conf <= 0.3:\n",
        "        print(\"\\nâœ… PASS - Low confidence as expected\")\n",
        "    else:\n",
        "        print(f\"\\nâš ï¸  WARNING - Expected {expected_confidence} confidence, got {conf:.2f}\")\n",
        "    \n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 1: Overview Question - Incident Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "â“ QUESTION: Describe what happened in the accident.\n",
            "======================================================================\n",
            "\n",
            "ðŸ“š Retrieving context for: 'Describe what happened in the accident.'\n",
            "   âœ… Retrieved 1 chunk(s)\n",
            "   ðŸ¤– Synthesizing answer with gpt-4o-mini...\n",
            "\n",
            "ðŸ“ ANSWER:\n",
            "The accident occurred on January 15, 2024, at approximately 2:30 PM on Interstate 95 in the northbound lane near Exit 42. At the time, weather conditions included heavy rain and poor visibility, estimated at 100 feet, which contributed to slow-moving traffic. The incident involved a 2020 Honda Accord, which was the claimant's vehicle, and a 2019 Toyota Camry, the other party's vehicle. The Honda Accord was traveling in the middle lane when traffic suddenly slowed. The driver attempted to brake but was unable to stop in time, resulting in a rear-end collision with the Toyota Camry ahead. Fortunately, no injuries were reported at the scene, and both drivers exchanged information and remained until police arrived, with a report filed under case number PD-2024-1234.\n",
            "\n",
            "ðŸŽ¯ CONFIDENCE:  0.90\n",
            "ðŸ“š SOURCES:     ['parent_001']\n",
            "ðŸ’¡ REASON:      The retrieved context provides a comprehensive overview of the accident, including the time, location, weather conditions, vehicles involved, and the sequence of events.\n",
            "\n",
            "âœ… PASS - High confidence as expected\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'answer': \"The accident occurred on January 15, 2024, at approximately 2:30 PM on Interstate 95 in the northbound lane near Exit 42. At the time, weather conditions included heavy rain and poor visibility, estimated at 100 feet, which contributed to slow-moving traffic. The incident involved a 2020 Honda Accord, which was the claimant's vehicle, and a 2019 Toyota Camry, the other party's vehicle. The Honda Accord was traveling in the middle lane when traffic suddenly slowed. The driver attempted to brake but was unable to stop in time, resulting in a rear-end collision with the Toyota Camry ahead. Fortunately, no injuries were reported at the scene, and both drivers exchanged information and remained until police arrived, with a report filed under case number PD-2024-1234.\",\n",
              " 'confidence': 0.9,\n",
              " 'sources': ['parent_001'],\n",
              " 'reason': 'The retrieved context provides a comprehensive overview of the accident, including the time, location, weather conditions, vehicles involved, and the sequence of events.'}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_question(\n",
        "    \"Describe what happened in the accident.\",\n",
        "    expected_confidence=\"high\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 2: Descriptive Question - Damage Assessment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "â“ QUESTION: Explain the damage to the vehicle and the repair process.\n",
            "======================================================================\n",
            "\n",
            "ðŸ“š Retrieving context for: 'Explain the damage to the vehicle and the repair process.'\n",
            "   âœ… Retrieved 3 chunk(s)\n",
            "   ðŸ¤– Synthesizing answer with gpt-4o-mini...\n",
            "\n",
            "ðŸ“ ANSWER:\n",
            "The vehicle, a 2020 Honda Accord, sustained significant damage primarily to the front bumper, which requires replacement. Additionally, the hood has a minor dent that can be repaired using paintless dent repair techniques. The front grille is cracked and also needs replacement, while the right headlight housing is cracked and requires a full replacement. The radiator shows no visible damage, but an inspection is recommended. The initial damage estimate is $4,500. \n",
            "\n",
            "The repair process began with the assignment of an adjuster, Sarah Johnson, on January 16, 2024, and the vehicle inspection was completed on January 18, 2024. The damage was noted to be consistent with a low-speed rear-end collision, and no structural damage was observed. Repairs were authorized on January 19, 2024, with the approved repair shop being AutoFix Collision Center. The estimated repair time is 5-7 business days, with all necessary parts in stock. The expected completion date for the repairs is January 29, 2024.\n",
            "\n",
            "ðŸŽ¯ CONFIDENCE:  0.90\n",
            "ðŸ“š SOURCES:     ['parent_002', 'parent_003', 'parent_004']\n",
            "ðŸ’¡ REASON:      The context provides comprehensive details about the vehicle damage and the repair process, including damage specifics, assessment, and timeline.\n",
            "\n",
            "âœ… PASS - High confidence as expected\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'answer': 'The vehicle, a 2020 Honda Accord, sustained significant damage primarily to the front bumper, which requires replacement. Additionally, the hood has a minor dent that can be repaired using paintless dent repair techniques. The front grille is cracked and also needs replacement, while the right headlight housing is cracked and requires a full replacement. The radiator shows no visible damage, but an inspection is recommended. The initial damage estimate is $4,500. \\n\\nThe repair process began with the assignment of an adjuster, Sarah Johnson, on January 16, 2024, and the vehicle inspection was completed on January 18, 2024. The damage was noted to be consistent with a low-speed rear-end collision, and no structural damage was observed. Repairs were authorized on January 19, 2024, with the approved repair shop being AutoFix Collision Center. The estimated repair time is 5-7 business days, with all necessary parts in stock. The expected completion date for the repairs is January 29, 2024.',\n",
              " 'confidence': 0.9,\n",
              " 'sources': ['parent_002', 'parent_003', 'parent_004'],\n",
              " 'reason': 'The context provides comprehensive details about the vehicle damage and the repair process, including damage specifics, assessment, and timeline.'}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_question(\n",
        "    \"Explain the damage to the vehicle and the repair process.\",\n",
        "    expected_confidence=\"high\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 3: Process Question - Claim Timeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "â“ QUESTION: Tell me about the claim processing timeline.\n",
            "======================================================================\n",
            "\n",
            "ðŸ“š Retrieving context for: 'Tell me about the claim processing timeline.'\n",
            "   âœ… Retrieved 1 chunk(s)\n",
            "   ðŸ¤– Synthesizing answer with gpt-4o-mini...\n",
            "\n",
            "ðŸ“ ANSWER:\n",
            "The claim processing timeline for Claim Number CLM-2024-00789 is as follows: The claim was filed online on January 15, 2024, at 6:45 PM, which was the same day as the incident. An initial review took place on January 16, 2024, at 9:00 AM, and the claim was approved shortly thereafter. The timeline includes several key steps: on January 16, the claim was assigned to adjuster Sarah Johnson, and initial contact was made with the claimant. A vehicle inspection was completed on January 18, followed by the approval of the damage estimate on the same day. On January 19, repair authorization was sent to AutoFix Collision Center, and repairs were scheduled to begin on January 22. The total amount approved for payment was $4,500, with a deductible of $500, resulting in $4,000 paid directly to the repair shop. The expected completion date for repairs is January 29, 2024.\n",
            "\n",
            "ðŸŽ¯ CONFIDENCE:  0.90\n",
            "ðŸ“š SOURCES:     ['parent_004']\n",
            "ðŸ’¡ REASON:      The retrieved context provides a comprehensive overview of the claim processing timeline, detailing each step from filing to payment.\n",
            "\n",
            "âœ… PASS - High confidence as expected\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'answer': 'The claim processing timeline for Claim Number CLM-2024-00789 is as follows: The claim was filed online on January 15, 2024, at 6:45 PM, which was the same day as the incident. An initial review took place on January 16, 2024, at 9:00 AM, and the claim was approved shortly thereafter. The timeline includes several key steps: on January 16, the claim was assigned to adjuster Sarah Johnson, and initial contact was made with the claimant. A vehicle inspection was completed on January 18, followed by the approval of the damage estimate on the same day. On January 19, repair authorization was sent to AutoFix Collision Center, and repairs were scheduled to begin on January 22. The total amount approved for payment was $4,500, with a deductible of $500, resulting in $4,000 paid directly to the repair shop. The expected completion date for repairs is January 29, 2024.',\n",
              " 'confidence': 0.9,\n",
              " 'sources': ['parent_004'],\n",
              " 'reason': 'The retrieved context provides a comprehensive overview of the claim processing timeline, detailing each step from filing to payment.'}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_question(\n",
        "    \"Tell me about the claim processing timeline.\",\n",
        "    expected_confidence=\"high\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 4: Multi-Entity Question - All Parties\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "â“ QUESTION: Who was involved in the accident and what are their details?\n",
            "======================================================================\n",
            "\n",
            "ðŸ“š Retrieving context for: 'Who was involved in the accident and what are their details?'\n",
            "   âœ… Retrieved 2 chunk(s)\n",
            "   ðŸ¤– Synthesizing answer with gpt-4o-mini...\n",
            "\n",
            "ðŸ“ ANSWER:\n",
            "The accident involved two vehicles: a 2020 Honda Accord, which was driven by the claimant, John Michael Doe, age 35, and a 2019 Toyota Camry, driven by another party. The Honda Accord is a silver, 4-door sedan with a VIN of 1HGCV1F30LA123456 and a license plate ABC-1234. At the time of the incident, the Honda Accord had a mileage of 45,230 miles and was registered to John Doe. No injuries were reported at the scene, and both drivers exchanged information before the police arrived.\n",
            "\n",
            "ðŸŽ¯ CONFIDENCE:  0.90\n",
            "ðŸ“š SOURCES:     ['parent_001', 'parent_002']\n",
            "ðŸ’¡ REASON:      The retrieved context provides comprehensive details about the individuals involved in the accident and their vehicle information.\n",
            "\n",
            "âœ… PASS - High confidence as expected\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'answer': 'The accident involved two vehicles: a 2020 Honda Accord, which was driven by the claimant, John Michael Doe, age 35, and a 2019 Toyota Camry, driven by another party. The Honda Accord is a silver, 4-door sedan with a VIN of 1HGCV1F30LA123456 and a license plate ABC-1234. At the time of the incident, the Honda Accord had a mileage of 45,230 miles and was registered to John Doe. No injuries were reported at the scene, and both drivers exchanged information before the police arrived.',\n",
              " 'confidence': 0.9,\n",
              " 'sources': ['parent_001', 'parent_002'],\n",
              " 'reason': 'The retrieved context provides comprehensive details about the individuals involved in the accident and their vehicle information.'}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_question(\n",
        "    \"Who was involved in the accident and what are their details?\",\n",
        "    expected_confidence=\"high\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 5: Comprehensive Question - Full Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "â“ QUESTION: Provide a complete summary of this insurance claim.\n",
            "======================================================================\n",
            "\n",
            "ðŸ“š Retrieving context for: 'Provide a complete summary of this insurance claim.'\n",
            "   âœ… Retrieved 4 chunk(s)\n",
            "   ðŸ¤– Synthesizing answer with gpt-4o-mini...\n",
            "\n",
            "ðŸ“ ANSWER:\n",
            "The insurance claim pertains to an accident that occurred on January 15, 2024, at approximately 2:30 PM on Interstate 95 in the northbound lane near Exit 42. The weather conditions included heavy rain and poor visibility, which contributed to slow-moving traffic. The incident involved a 2020 Honda Accord, owned by the claimant John Michael Doe, and a 2019 Toyota Camry. The Honda Accord rear-ended the Toyota Camry after the traffic ahead slowed unexpectedly. Fortunately, no injuries were reported at the scene, and both drivers exchanged information until police arrived, resulting in a police report filed under case number PD-2024-1234.\n",
            "\n",
            "The initial damage assessment for the Honda Accord estimated damages at $4,500, with significant damage to the front bumper requiring replacement, minor dent repair on the hood, and a cracked front grille and right headlight housing that also needed replacement. An adjuster, Sarah Johnson, was assigned on January 16, 2024, and the vehicle inspection was completed on January 18, 2024. The damage was consistent with a low-speed rear-end collision, and no structural damage was observed.\n",
            "\n",
            "The claim was filed on the same day as the incident, January 15, 2024, and was approved by January 16, 2024. The total approved payment for repairs was $4,500, with a $500 deductible, resulting in a direct payment of $4,000 to the repair shop, AutoFix Collision Center. Repairs are scheduled to begin on January 22, 2024, with an expected completion date of January 29, 2024.\n",
            "\n",
            "ðŸŽ¯ CONFIDENCE:  0.90\n",
            "ðŸ“š SOURCES:     ['parent_001', 'parent_002', 'parent_003', 'parent_004']\n",
            "ðŸ’¡ REASON:      The retrieved context provides comprehensive coverage of the insurance claim, including details about the accident, damage assessment, and claim processing timeline.\n",
            "\n",
            "âœ… PASS - High confidence as expected\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'answer': 'The insurance claim pertains to an accident that occurred on January 15, 2024, at approximately 2:30 PM on Interstate 95 in the northbound lane near Exit 42. The weather conditions included heavy rain and poor visibility, which contributed to slow-moving traffic. The incident involved a 2020 Honda Accord, owned by the claimant John Michael Doe, and a 2019 Toyota Camry. The Honda Accord rear-ended the Toyota Camry after the traffic ahead slowed unexpectedly. Fortunately, no injuries were reported at the scene, and both drivers exchanged information until police arrived, resulting in a police report filed under case number PD-2024-1234.\\n\\nThe initial damage assessment for the Honda Accord estimated damages at $4,500, with significant damage to the front bumper requiring replacement, minor dent repair on the hood, and a cracked front grille and right headlight housing that also needed replacement. An adjuster, Sarah Johnson, was assigned on January 16, 2024, and the vehicle inspection was completed on January 18, 2024. The damage was consistent with a low-speed rear-end collision, and no structural damage was observed.\\n\\nThe claim was filed on the same day as the incident, January 15, 2024, and was approved by January 16, 2024. The total approved payment for repairs was $4,500, with a $500 deductible, resulting in a direct payment of $4,000 to the repair shop, AutoFix Collision Center. Repairs are scheduled to begin on January 22, 2024, with an expected completion date of January 29, 2024.',\n",
              " 'confidence': 0.9,\n",
              " 'sources': ['parent_001', 'parent_002', 'parent_003', 'parent_004'],\n",
              " 'reason': 'The retrieved context provides comprehensive coverage of the insurance claim, including details about the accident, damage assessment, and claim processing timeline.'}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_question(\n",
        "    \"Provide a complete summary of this insurance claim.\",\n",
        "    expected_confidence=\"high\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 6: Partial Context - Limited Information\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "â“ QUESTION: Describe any injuries sustained in the accident.\n",
            "======================================================================\n",
            "\n",
            "ðŸ“š Retrieving context for: 'Describe any injuries sustained in the accident.'\n",
            "   âœ… Retrieved 2 chunk(s)\n",
            "   ðŸ¤– Synthesizing answer with gpt-4o-mini...\n",
            "\n",
            "ðŸ“ ANSWER:\n",
            "The retrieved context indicates that no injuries were reported at the scene of the accident involving the 2020 Honda Accord and the 2019 Toyota Camry. Both drivers exchanged information and remained at the location until police arrived.\n",
            "\n",
            "ðŸŽ¯ CONFIDENCE:  0.90\n",
            "ðŸ“š SOURCES:     ['parent_001']\n",
            "ðŸ’¡ REASON:      The context clearly states that no injuries were reported, providing comprehensive coverage of the injury aspect of the accident.\n",
            "\n",
            "âš ï¸  WARNING - Expected low confidence, got 0.90\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'answer': 'The retrieved context indicates that no injuries were reported at the scene of the accident involving the 2020 Honda Accord and the 2019 Toyota Camry. Both drivers exchanged information and remained at the location until police arrived.',\n",
              " 'confidence': 0.9,\n",
              " 'sources': ['parent_001'],\n",
              " 'reason': 'The context clearly states that no injuries were reported, providing comprehensive coverage of the injury aspect of the accident.'}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_question(\n",
        "    \"Describe any injuries sustained in the accident.\",\n",
        "    expected_confidence=\"low\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ“Š Batch Testing\n",
        "\n",
        "Run all test questions in batch for quick validation:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "ðŸ§ª BATCH TEST RESULTS\n",
            "======================================================================\n",
            "\n",
            "ðŸ“š Retrieving context for: 'Describe what happened in the accident.'\n",
            "   âœ… Retrieved 1 chunk(s)\n",
            "   ðŸ¤– Synthesizing answer with gpt-4o-mini...\n",
            "\n",
            "âœ… PASS\n",
            "  Q: Describe what happened in the accident.\n",
            "  Confidence: 0.90 (expected: high)\n",
            "  Answer length: 745 chars\n",
            "  Sources: 1 chunks\n",
            "\n",
            "ðŸ“š Retrieving context for: 'Explain the damage to the vehicle and the repair process.'\n",
            "   âœ… Retrieved 3 chunk(s)\n",
            "   ðŸ¤– Synthesizing answer with gpt-4o-mini...\n",
            "\n",
            "âœ… PASS\n",
            "  Q: Explain the damage to the vehicle and the repair process.\n",
            "  Confidence: 0.90 (expected: high)\n",
            "  Answer length: 995 chars\n",
            "  Sources: 3 chunks\n",
            "\n",
            "ðŸ“š Retrieving context for: 'Tell me about the claim processing timeline.'\n",
            "   âœ… Retrieved 1 chunk(s)\n",
            "   ðŸ¤– Synthesizing answer with gpt-4o-mini...\n",
            "\n",
            "âœ… PASS\n",
            "  Q: Tell me about the claim processing timeline.\n",
            "  Confidence: 0.90 (expected: high)\n",
            "  Answer length: 850 chars\n",
            "  Sources: 1 chunks\n",
            "\n",
            "ðŸ“š Retrieving context for: 'Who was involved in the accident?'\n",
            "   âœ… Retrieved 2 chunk(s)\n",
            "   ðŸ¤– Synthesizing answer with gpt-4o-mini...\n",
            "\n",
            "âœ… PASS\n",
            "  Q: Who was involved in the accident?\n",
            "  Confidence: 0.90 (expected: high)\n",
            "  Answer length: 290 chars\n",
            "  Sources: 2 chunks\n",
            "\n",
            "ðŸ“š Retrieving context for: 'Provide a complete summary of this insurance claim.'\n",
            "   âœ… Retrieved 4 chunk(s)\n",
            "   ðŸ¤– Synthesizing answer with gpt-4o-mini...\n",
            "\n",
            "âœ… PASS\n",
            "  Q: Provide a complete summary of this insurance claim.\n",
            "  Confidence: 0.90 (expected: high)\n",
            "  Answer length: 1358 chars\n",
            "  Sources: 4 chunks\n",
            "\n",
            "ðŸ“š Retrieving context for: 'Describe any injuries sustained in the accident.'\n",
            "   âœ… Retrieved 2 chunk(s)\n",
            "   ðŸ¤– Synthesizing answer with gpt-4o-mini...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m failed = \u001b[32m0\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m question, expected_conf \u001b[38;5;129;01min\u001b[39;00m test_cases:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     result = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43manswer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmock_retriever\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     conf = result[\u001b[33m'\u001b[39m\u001b[33mconfidence\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# Check if confidence matches expectation\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/AI Lecture/FIRST PROJECT/RagAgentv2/RAG/Agents/summary_agent.py:385\u001b[39m, in \u001b[36mSummaryAgent.answer\u001b[39m\u001b[34m(self, question, retriever)\u001b[39m\n\u001b[32m    381\u001b[39m \u001b[38;5;66;03m# Step 5: Get LLM response\u001b[39;00m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# WHY: LLM synthesizes context into coherent explanation\u001b[39;00m\n\u001b[32m    383\u001b[39m \u001b[38;5;66;03m# WHY: Temperature=0.2 ensures coherence without hallucination\u001b[39;00m\n\u001b[32m    384\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   ðŸ¤– Synthesizing answer with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.model\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatted_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[38;5;66;03m# Step 6: Parse structured output\u001b[39;00m\n\u001b[32m    388\u001b[39m \u001b[38;5;66;03m# WHY: Validates response matches SummaryAnswer schema\u001b[39;00m\n\u001b[32m    389\u001b[39m \u001b[38;5;66;03m# WHY: Handles edge cases gracefully\u001b[39;00m\n\u001b[32m    390\u001b[39m content = response.content \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.content, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(response.content)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1377\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1370\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[32m   1371\u001b[39m             response,\n\u001b[32m   1372\u001b[39m             schema=original_schema_obj,\n\u001b[32m   1373\u001b[39m             metadata=generation_info,\n\u001b[32m   1374\u001b[39m             output_version=\u001b[38;5;28mself\u001b[39m.output_version,\n\u001b[32m   1375\u001b[39m         )\n\u001b[32m   1376\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1377\u001b[39m         raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1378\u001b[39m         response = raw_response.parse()\n\u001b[32m   1379\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/openai/_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:1192\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1145\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1147\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1189\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1190\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1191\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/openai/_base_client.py:982\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    980\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    988\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/ssl.py:1295\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1291\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1292\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1293\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1294\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ragagent/lib/python3.11/ssl.py:1168\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Define test cases\n",
        "test_cases = [\n",
        "    (\"Describe what happened in the accident.\", \"high\"),\n",
        "    (\"Explain the damage to the vehicle and the repair process.\", \"high\"),\n",
        "    (\"Tell me about the claim processing timeline.\", \"high\"),\n",
        "    (\"Who was involved in the accident?\", \"high\"),\n",
        "    (\"Provide a complete summary of this insurance claim.\", \"high\"),\n",
        "    (\"Describe any injuries sustained in the accident.\", \"low\"),\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ðŸ§ª BATCH TEST RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "passed = 0\n",
        "failed = 0\n",
        "\n",
        "for question, expected_conf in test_cases:\n",
        "    result = agent.answer(question, mock_retriever)\n",
        "    conf = result['confidence']\n",
        "    \n",
        "    # Check if confidence matches expectation\n",
        "    if expected_conf == \"high\":\n",
        "        test_passed = conf > 0.7\n",
        "    elif expected_conf == \"medium\":\n",
        "        test_passed = 0.4 <= conf <= 0.7\n",
        "    else:  # low\n",
        "        test_passed = conf <= 0.3\n",
        "    \n",
        "    status = \"âœ… PASS\" if test_passed else \"âŒ FAIL\"\n",
        "    passed += 1 if test_passed else 0\n",
        "    failed += 0 if test_passed else 1\n",
        "    \n",
        "    print(f\"\\n{status}\")\n",
        "    print(f\"  Q: {question}\")\n",
        "    print(f\"  Confidence: {conf:.2f} (expected: {expected_conf})\")\n",
        "    print(f\"  Answer length: {len(result['answer'])} chars\")\n",
        "    print(f\"  Sources: {len(result['sources'])} chunks\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"ðŸ“Š SUMMARY: {passed} passed, {failed} failed out of {len(test_cases)} tests\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ” Comparison: Summary vs Needle Agent\n",
        "\n",
        "Let's highlight the key differences:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "NEEDLE AGENT vs SUMMARY AGENT\n",
            "======================================================================\n",
            "\n",
            "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "â”‚ Aspect           â”‚ Needle Agent           â”‚ Summary Agent          â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ Question Type    â”‚ Single atomic fact     â”‚ Multiple facts/context â”‚\n",
            "â”‚ Temperature      â”‚ 0.0 (deterministic)    â”‚ 0.2 (coherent)         â”‚\n",
            "â”‚ Retrieval        â”‚ Child chunks only      â”‚ Auto-Merged (parent)   â”‚\n",
            "â”‚ Threshold        â”‚ High similarity        â”‚ No threshold           â”‚\n",
            "â”‚ Answer Length    â”‚ Short (1 phrase)       â”‚ Multi-paragraph        â”‚\n",
            "â”‚ Chunks Used      â”‚ ONE most relevant      â”‚ ALL relevant chunks    â”‚\n",
            "â”‚ Null Answer      â”‚ Returns null if absent â”‚ Always provides answer â”‚\n",
            "â”‚ Confidence       â”‚ Based on match quality â”‚ Based on coverage      â”‚\n",
            "â”‚ Use Case         â”‚ \"What is X?\"           â”‚ \"Describe/Explain X\"   â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "Examples:\n",
            "\n",
            "NEEDLE QUESTIONS:\n",
            "  âœ“ \"What is the claim number?\"\n",
            "  âœ“ \"When did the accident occur?\"\n",
            "  âœ“ \"What is the VIN?\"\n",
            "\n",
            "SUMMARY QUESTIONS:\n",
            "  âœ“ \"Describe the accident circumstances.\"\n",
            "  âœ“ \"Explain the damage assessment process.\"\n",
            "  âœ“ \"Tell me about the claim timeline.\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"NEEDLE AGENT vs SUMMARY AGENT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "comparison = \"\"\"\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚ Aspect           â”‚ Needle Agent           â”‚ Summary Agent          â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ Question Type    â”‚ Single atomic fact     â”‚ Multiple facts/context â”‚\n",
        "â”‚ Temperature      â”‚ 0.0 (deterministic)    â”‚ 0.2 (coherent)         â”‚\n",
        "â”‚ Retrieval        â”‚ Child chunks only      â”‚ Auto-Merged (parent)   â”‚\n",
        "â”‚ Threshold        â”‚ High similarity        â”‚ No threshold           â”‚\n",
        "â”‚ Answer Length    â”‚ Short (1 phrase)       â”‚ Multi-paragraph        â”‚\n",
        "â”‚ Chunks Used      â”‚ ONE most relevant      â”‚ ALL relevant chunks    â”‚\n",
        "â”‚ Null Answer      â”‚ Returns null if absent â”‚ Always provides answer â”‚\n",
        "â”‚ Confidence       â”‚ Based on match quality â”‚ Based on coverage      â”‚\n",
        "â”‚ Use Case         â”‚ \"What is X?\"           â”‚ \"Describe/Explain X\"   â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "Examples:\n",
        "\n",
        "NEEDLE QUESTIONS:\n",
        "  âœ“ \"What is the claim number?\"\n",
        "  âœ“ \"When did the accident occur?\"\n",
        "  âœ“ \"What is the VIN?\"\n",
        "\n",
        "SUMMARY QUESTIONS:\n",
        "  âœ“ \"Describe the accident circumstances.\"\n",
        "  âœ“ \"Explain the damage assessment process.\"\n",
        "  âœ“ \"Tell me about the claim timeline.\"\n",
        "\"\"\"\n",
        "\n",
        "print(comparison)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## âœ… Conclusion\n",
        "\n",
        "The **Summary Agent** is production-ready and follows all architectural constraints:\n",
        "\n",
        "âœ… Uses LangChain ONLY  \n",
        "âœ… Retriever is injected (no FAISS, no embeddings)  \n",
        "âœ… Structured output (Pydantic)  \n",
        "âœ… Synthesizes context (no guessing)  \n",
        "âœ… Source traceability (chunk IDs)  \n",
        "âœ… Temperature 0.2 (coherent synthesis)  \n",
        "âœ… Self-contained tests (mock retriever)  \n",
        "\n",
        "**Key Differences from Needle Agent:**\n",
        "- ðŸ“š Uses **multiple chunks** vs single chunk\n",
        "- ðŸŒ¡ï¸ **Temperature 0.2** vs 0.0 for coherence\n",
        "- ðŸ“ **Multi-paragraph** answers vs short phrases\n",
        "- ðŸŽ¯ **High recall** (no threshold) vs high precision\n",
        "- âœ… **Always answers** vs returns null when not found\n",
        "\n",
        "**Next Steps:**\n",
        "- Integrate with Router Agent\n",
        "- Create orchestration layer (Router â†’ Needle/Summary)\n",
        "- End-to-end RAG pipeline\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ragagent",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
