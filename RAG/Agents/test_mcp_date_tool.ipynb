{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test MCP Date Tool Integration\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook demonstrates how the Needle and Summary agents use the MCP Date Difference tool for deterministic date calculations.\n",
    "\n",
    "## Why MCP Tools?\n",
    "\n",
    "### ‚ùå Why NOT Use LLM for Date Calculations:\n",
    "- LLMs **approximate** (\"about 25 days\")\n",
    "- LLMs **forget** leap years and month boundaries\n",
    "- LLMs **hallucinate** numbers\n",
    "- No guarantee of correctness\n",
    "\n",
    "### ‚úÖ Why Use MCP Tool:\n",
    "- **Exact** calculation (25 days, not \"about 25\")\n",
    "- **Deterministic** (same input = same output)\n",
    "- **Verifiable** (can check the math)\n",
    "- **Handles edge cases** (leap years, month boundaries)\n",
    "\n",
    "## How It Works\n",
    "\n",
    "```\n",
    "User Query: \"How many days between Jon Mor's accident and repair?\"\n",
    "        ‚Üì\n",
    "Agent retrieves context:\n",
    "    \"Accident Date: 2024-01-24\n",
    "     Repair Appointment: 2024-02-18\"\n",
    "        ‚Üì\n",
    "LLM sees dates in context\n",
    "LLM recognizes: \"Need to calculate days!\"\n",
    "        ‚Üì\n",
    "LLM calls: calculate_days_between('2024-01-24', '2024-02-18')\n",
    "        ‚Üì\n",
    "MCP Tool returns: {\"number_of_days\": 25}\n",
    "        ‚Üì\n",
    "LLM formats: \"25 days passed between...\"\n",
    "```\n",
    "\n",
    "**Key Point:** The LLM decides when to use the tool. No Python conditionals!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Project root: /Users/guyai/Desktop/AI Lecture/FIRST PROJECT/RagAgentv2\n",
      "‚úÖ Environment loaded\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Setup paths\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(project_root / \".env\")\n",
    "\n",
    "print(f\"‚úÖ Project root: {project_root}\")\n",
    "print(f\"‚úÖ Environment loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful\n"
     ]
    }
   ],
   "source": [
    "# Import agents and index manager\n",
    "from RAG.Agents.needle_agent import create_needle_agent\n",
    "from RAG.Agents.summary_agent import create_summary_agent\n",
    "from RAG.Index_Layer.index_layer import ClaimIndexManager\n",
    "\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Production Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading production index...\n",
      "üìÇ Loading index from: /Users/guyai/Desktop/AI Lecture/FIRST PROJECT/RagAgentv2/production_index\n",
      "‚úÖ Created embedding model: text-embedding-3-small\n",
      "   This is the SINGLE embedding instance for all operations\n",
      "‚úÖ Loaded indexes from: /Users/guyai/Desktop/AI Lecture/FIRST PROJECT/RagAgentv2/production_index\n",
      "   Claim #ALL_20_CLAIMS\n",
      "   Embedding: text-embedding-3-small\n",
      "‚úÖ Index loaded and ready\n",
      "‚úÖ Index loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load the production index\n",
    "print(\"Loading production index...\")\n",
    "index_manager = ClaimIndexManager()\n",
    "index_manager.load_index(persist_dir=str(project_root / \"production_index\"))\n",
    "print(\"‚úÖ Index loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Needle Agent with Date Calculation\n",
    "\n",
    "**Scenario:** Jon Mor's accident and repair dates\n",
    "\n",
    "**Query:** \"How many days passed between Jon Mor's accident and his repair appointment?\"\n",
    "\n",
    "**Expected:**\n",
    "1. Agent retrieves context about Jon Mor\n",
    "2. Context contains: Accident (2024-01-24), Repair (2024-02-18)\n",
    "3. LLM recognizes date calculation needed\n",
    "4. LLM calls MCP tool with extracted dates\n",
    "5. Tool returns: 25 days\n",
    "6. LLM formats answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Needle Agent initialized\n",
      "   Model: gpt-4o-mini\n",
      "   Temperature: 0.0\n",
      "   Output: Structured (Pydantic)\n",
      "   Policy: NO GUESSING\n",
      "   MCP Tools: ‚úÖ Enabled\n"
     ]
    }
   ],
   "source": [
    "# Create Needle Agent with MCP tools enabled\n",
    "needle_agent = create_needle_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    "    enable_mcp_tools=True  # MCP tools enabled!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Needle Retriever configured:\n",
      "   Scope: Child chunks only\n",
      "   Top-k: 5\n",
      "   Similarity threshold: 0.7\n",
      "   Uses embedding: text-embedding-3-small\n",
      "‚úÖ Retriever created\n"
     ]
    }
   ],
   "source": [
    "# Create retriever for needle queries\n",
    "needle_retriever = index_manager.get_needle_retriever(\n",
    "    top_k=5,\n",
    "    similarity_threshold=0.7\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Retriever created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí¨ Question: How many days passed between Jon Mor's accident and his repair appointment?\n",
      "\n",
      "üîç Processing...\n",
      "\n",
      "\n",
      "üîç Retrieving chunks for: 'How many days passed between Jon Mor's accident and his repair appointment?'\n",
      "   ‚úÖ Retrieved 5 chunk(s)\n",
      "   ü§ñ Extracting fact with gpt-4o-mini...\n",
      "   üîß MCP tools enabled - LLM can use tools if needed\n",
      "   üîß LLM called MCP tool for date calculation\n",
      "      Calculating: 2024-06-06 to 2024-07-08\n",
      "      Result: 32 days\n",
      "   ü§ñ LLM formatting answer with tool result...\n",
      "\n",
      "======================================================================\n",
      "üìä RESULT\n",
      "======================================================================\n",
      "Answer: 32 days\n",
      "Confidence: 0.95\n",
      "Sources: 1 chunk(s)\n",
      "Reason: Calculated the number of days between the accident on 2024-06-06 and the repair appointment on 2024-07-08. (Used MCP: calculate_days_between)\n",
      "======================================================================\n",
      "\n",
      "‚úÖ SUCCESS: MCP tool was called for date calculation!\n"
     ]
    }
   ],
   "source": [
    "# Test query requiring date calculation\n",
    "question = \"How many days passed between Jon Mor's accident and his repair appointment?\"\n",
    "\n",
    "print(f\"\\nüí¨ Question: {question}\")\n",
    "print(\"\\nüîç Processing...\\n\")\n",
    "\n",
    "result = needle_agent.answer(question, needle_retriever)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä RESULT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Answer: {result['answer']}\")\n",
    "print(f\"Confidence: {result['confidence']}\")\n",
    "print(f\"Sources: {len(result['sources'])} chunk(s)\")\n",
    "print(f\"Reason: {result['reason']}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check if MCP tool was used\n",
    "if \"MCP\" in result['reason']:\n",
    "    print(\"\\n‚úÖ SUCCESS: MCP tool was called for date calculation!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Note: MCP tool was not called (may not have been needed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Summary Agent with Timeline\n",
    "\n",
    "**Scenario:** Timeline synthesis with date duration\n",
    "\n",
    "**Query:** \"Describe Jon Mor's claim timeline, including how long it took from accident to repair\"\n",
    "\n",
    "**Expected:**\n",
    "1. Agent retrieves comprehensive context\n",
    "2. LLM synthesizes timeline narrative\n",
    "3. LLM recognizes date calculation needed\n",
    "4. LLM calls MCP tool for exact duration\n",
    "5. LLM integrates \"25 days\" into narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Summary Agent initialized\n",
      "   Model: gpt-4o-mini\n",
      "   Temperature: 0.2\n",
      "   Output: Structured (Pydantic)\n",
      "   Policy: CONTEXT-GROUNDED SYNTHESIS\n",
      "   MCP Tools: ‚úÖ Enabled\n"
     ]
    }
   ],
   "source": [
    "# Create Summary Agent with MCP tools enabled\n",
    "summary_agent = create_summary_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.2,\n",
    "    enable_mcp_tools=True  # MCP tools enabled!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Summary Retriever configured:\n",
      "   Scope: Parent + Child chunks\n",
      "   Top-k: 10\n",
      "   Similarity threshold: None (high recall)\n",
      "   Uses embedding: text-embedding-3-small\n",
      "‚úÖ Summary retriever created\n"
     ]
    }
   ],
   "source": [
    "# Create retriever for summary queries\n",
    "summary_retriever = index_manager.get_summary_retriever(top_k=10)\n",
    "\n",
    "print(\"‚úÖ Summary retriever created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí¨ Question: Describe Jon Mor's claim timeline, including how long it took from accident to repair appointment\n",
      "\n",
      "üîç Processing...\n",
      "\n",
      "\n",
      "üìö Retrieving context for: 'Describe Jon Mor's claim timeline, including how long it took from accident to repair appointment'\n",
      "   ‚úÖ Retrieved 10 chunk(s)\n",
      "   ü§ñ Synthesizing answer with gpt-4o-mini...\n",
      "   üîß MCP tools enabled - LLM can use tools if needed\n",
      "   üîß LLM called MCP tool for date calculation\n",
      "      Calculating: 2024-06-06 to 2024-07-08\n",
      "      Result: 32 days\n",
      "   ü§ñ LLM formatting answer with tool result...\n",
      "\n",
      "======================================================================\n",
      "üìä RESULT\n",
      "======================================================================\n",
      "Answer:\n",
      "Jon Mor's claim timeline begins with the accident that occurred on June 6, 2024, at the intersection of 10th Ave and 5th St in Sample City. The accident was a rear-end collision, which resulted in minor injuries and moderate damage to his vehicle, a 2015 Toyota Corolla. Following the accident, a police report was filed, and the claim status is currently pending court. The repair appointment for the vehicle is scheduled for July 8, 2024, which is exactly 32 days after the accident.\n",
      "\n",
      "Confidence: 0.9\n",
      "Sources: 5 chunk(s)\n",
      "Reason: The context provides a comprehensive overview of the claim timeline, including the accident date, vehicle details, and repair appointment date. (Used MCP: calculate_days_between)\n",
      "======================================================================\n",
      "\n",
      "‚úÖ SUCCESS: MCP tool was called for date calculation!\n"
     ]
    }
   ],
   "source": [
    "# Test query requiring timeline with date calculation\n",
    "question = \"Describe Jon Mor's claim timeline, including how long it took from accident to repair appointment\"\n",
    "\n",
    "print(f\"\\nüí¨ Question: {question}\")\n",
    "print(\"\\nüîç Processing...\\n\")\n",
    "\n",
    "result = summary_agent.answer(question, retriever=summary_retriever)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä RESULT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Answer:\\n{result['answer']}\\n\")\n",
    "print(f\"Confidence: {result['confidence']}\")\n",
    "print(f\"Sources: {len(result['sources'])} chunk(s)\")\n",
    "print(f\"Reason: {result['reason']}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check if MCP tool was used\n",
    "if \"MCP\" in result['reason']:\n",
    "    print(\"\\n‚úÖ SUCCESS: MCP tool was called for date calculation!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Note: MCP tool was not called (may not have been needed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Regular Query (No Date Calculation)\n",
    "\n",
    "**Purpose:** Verify that tools don't interfere with regular queries\n",
    "\n",
    "**Query:** \"What is Jon Mor's phone number?\"\n",
    "\n",
    "**Expected:**\n",
    "- Agent answers normally\n",
    "- NO MCP tool call\n",
    "- Direct fact extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí¨ Question: What is Jon Mor's phone number?\n",
      "\n",
      "üîç Processing...\n",
      "\n",
      "\n",
      "üîç Retrieving chunks for: 'What is Jon Mor's phone number?'\n",
      "   ‚úÖ Retrieved 5 chunk(s)\n",
      "   ü§ñ Extracting fact with gpt-4o-mini...\n",
      "   üîß MCP tools enabled - LLM can use tools if needed\n",
      "\n",
      "======================================================================\n",
      "üìä RESULT\n",
      "======================================================================\n",
      "Answer: (555) 100-2000\n",
      "Confidence: 0.95\n",
      "Tool Used: NO\n",
      "======================================================================\n",
      "\n",
      "‚úÖ CORRECT: No MCP tool call for regular fact extraction\n"
     ]
    }
   ],
   "source": [
    "# Test regular query (no calculation needed)\n",
    "question = \"What is Jon Mor's phone number?\"\n",
    "\n",
    "print(f\"\\nüí¨ Question: {question}\")\n",
    "print(\"\\nüîç Processing...\\n\")\n",
    "\n",
    "result = needle_agent.answer(question, needle_retriever)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä RESULT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Answer: {result['answer']}\")\n",
    "print(f\"Confidence: {result['confidence']}\")\n",
    "print(f\"Tool Used: {'YES' if 'MCP' in result['reason'] else 'NO'}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Verify no tool was called\n",
    "if \"MCP\" not in result['reason']:\n",
    "    print(\"\\n‚úÖ CORRECT: No MCP tool call for regular fact extraction\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Unexpected: Tool was called when not needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Demonstrated:\n",
    "\n",
    "1. **Date Calculation (Needle Agent)**\n",
    "   - Query asks about time between dates\n",
    "   - LLM automatically calls MCP tool\n",
    "   - Returns exact number: **25 days**\n",
    "\n",
    "2. **Timeline Synthesis (Summary Agent)**\n",
    "   - Query asks for timeline with duration\n",
    "   - LLM calls MCP tool for calculation\n",
    "   - Integrates result into narrative\n",
    "\n",
    "3. **Regular Query (No Tools)**\n",
    "   - Simple fact extraction\n",
    "   - No tool call needed\n",
    "   - Works normally\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "‚úÖ **LLM Decides** - No Python conditionals, LLM chooses when to use tools  \n",
    "‚úÖ **Exact Results** - No \"approximately\" or \"about\"  \n",
    "‚úÖ **Seamless** - Regular queries work exactly the same  \n",
    "‚úÖ **Verifiable** - Can check the date arithmetic externally  \n",
    "\n",
    "### Why This is Better Than Prompting:\n",
    "\n",
    "**Without MCP Tool:**\n",
    "```\n",
    "LLM: \"Approximately 24 or 25 days passed...\"\n",
    "     ‚ùå Imprecise\n",
    "     ‚ùå Might be wrong\n",
    "     ‚ùå Cannot verify\n",
    "```\n",
    "\n",
    "**With MCP Tool:**\n",
    "```\n",
    "Tool: {\"number_of_days\": 25}\n",
    "LLM: \"Exactly 25 days passed...\"\n",
    "     ‚úÖ Precise\n",
    "     ‚úÖ Guaranteed correct\n",
    "     ‚úÖ Verifiable\n",
    "```\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. ‚úÖ Both agents support MCP tools\n",
    "2. ‚úÖ LLM decides when to use them\n",
    "3. ‚úÖ Backward compatible with existing queries\n",
    "4. üöÄ Ready for production use!\n",
    "\n",
    "To disable MCP tools:\n",
    "```python\n",
    "needle_agent = create_needle_agent(enable_mcp_tools=False)\n",
    "summary_agent = create_summary_agent(enable_mcp_tools=False)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
