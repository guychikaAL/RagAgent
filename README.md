# RAG Agent v2 - Production-Grade RAG System

A modular, scalable Retrieval-Augmented Generation (RAG) system designed for production use with **multi-claim document processing** and **smart metadata filtering**.

Advanced RAG system for insurance claims using multi-agent AI architecture. Automatically routes questions to specialized agents, uses auto-merging retrieval for precise answers, handles complex summaries with map-reduce, and performs date calculations with MCP tools. Includes GUI showing retrieval processes and complete evaluation framework.

## ğŸš€ Quick Start

 Interactive Script
```bash
# Build production index (once)
python build_production_index.py

# Query the system
python main.py
# Then type questions interactively

or GUI experience

# Build production index (once)
python build_production_index.py

# Launch web interface
streamlit run app/gui_app.py
```
you might need enter your email for GUI expirience

evaluation
```bash
#ragas evaluation
python evaluation-ragas/ragas_eval.py

#custom llm as a jusge evaluation (need to enter gemini api key in .env GOOGLE_API_KEY="")
python evaluation/run_evaluation.py 
```

### Supported Query Formats
âœ… **By claim number**: "Summarize claim number 5", "What is form #1 about?"  
âœ… **By claimant name**: "What is Eli Cohen's phone number?", "Summarize Jon Mor's claim"  
âœ… **All 20 claims**: Indexed and searchable simultaneously

---

## Architecture


# ğŸ”„ **FLOWS SECTION**

## **Overview: Two Critical Flows**

The RagAgentv2 system operates through **two distinct flows** that work together to enable fast, accurate question answering:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚  FLOW 1: BUILD PRODUCTION INDEX (One-Time)              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚  Raw PDF â†’ Searchable Vector Database                   â”‚
â”‚  Duration: 5-10 minutes                                 â”‚
â”‚  Frequency: Once (or when data changes)                 â”‚
â”‚                                                         â”‚
â”‚                                                         â”‚
â”‚  FLOW 2: QUERY TIME (Every Question)                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚  User Question â†’ Intelligent Answer                     â”‚
â”‚  Duration: 2-5 seconds                                  â”‚
â”‚  Frequency: Every user query                            â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## **FLOW 1: Build Production Index (Build Time)**

### **Complete Flow Diagram:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FLOW 1: BUILD INDEX                         â”‚
â”‚                      (Run Once)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  ğŸ“„ INPUT: auto_claim_20_forms_FINAL.pdf                                â”‚
â”‚            (45 pages, 20 insurance claims)                               â”‚
â”‚                                                                          â”‚
â”‚     â†“                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  STAGE 1.1: PDF INGESTION                                       â”‚    â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚    â”‚
â”‚  â”‚  File: RAG/PDF_Ingestion/pdf_ingestion.py                       â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Process:                                                        â”‚    â”‚
â”‚  â”‚  1. Validate PDF file (exists, readable, not encrypted)         â”‚    â”‚
â”‚  â”‚  2. Extract text from all 45 pages                              â”‚    â”‚
â”‚  â”‚  3. Remove page numbers and artifacts                           â”‚    â”‚
â”‚  â”‚  4. Fix broken line breaks (automo-\nbile â†’ automobile)         â”‚    â”‚
â”‚  â”‚  5. Normalize whitespace and reconstruct paragraphs             â”‚    â”‚
â”‚  â”‚  6. Extract metadata (pages, words, dates, etc.)                â”‚    â”‚
â”‚  â”‚  7. Create LlamaIndex Document object                           â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Output: 1 Document (clean text + metadata)                     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚     â†“                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  STAGE 1.2: CLAIM SEGMENTATION                                  â”‚    â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚    â”‚
â”‚  â”‚  File: RAG/Claim_Segmentation/claim_segmentation.py             â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Process:                                                        â”‚    â”‚
â”‚  â”‚  1. Detect claim boundaries ("AUTO CLAIM FORM #N")              â”‚    â”‚
â”‚  â”‚  2. Extract text slice for each claim                           â”‚    â”‚
â”‚  â”‚  3. Extract claimant name dynamically (e.g., "Jon Mor")         â”‚    â”‚
â”‚  â”‚  4. Generate unique claim_id for each claim                     â”‚    â”‚
â”‚  â”‚  5. Add claim-specific metadata                                 â”‚    â”‚
â”‚  â”‚  6. Create separate Document for each claim                     â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Output: 20 Documents (one per claim)                           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚     â†“                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  STAGE 1.3: CHUNKING LAYER                                      â”‚    â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚    â”‚
â”‚  â”‚  File: RAG/Chunking_Layer/chunking_layer.py                     â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Process:                                                        â”‚    â”‚
â”‚  â”‚  1. Detect sections (SECTION N â€“ TITLE patterns)                â”‚    â”‚
â”‚  â”‚     â””â”€ Create IndexNode for each section                        â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  2. Create parent chunks (~800 characters each)                 â”‚    â”‚
â”‚  â”‚     â””â”€ Prepend claim context to each parent                     â”‚    â”‚
â”‚  â”‚     â””â”€ Create TextNode for each parent                          â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  3. Create child chunks (~200 characters each)                  â”‚    â”‚
â”‚  â”‚     â””â”€ Split parents into smaller chunks                        â”‚    â”‚
â”‚  â”‚     â””â”€ Create TextNode for each child                           â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  4. Link relationships (section â†’ parent â†’ child)               â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  5. Enrich metadata (chunk_id, claim_id, position, etc.)        â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Hierarchy: 3 Levels                                            â”‚    â”‚
â”‚  â”‚  â€¢ Sections: Navigational structure                             â”‚    â”‚
â”‚  â”‚  â€¢ Parents: Broad context (~800 chars)                          â”‚    â”‚
â”‚  â”‚  â€¢ Children: Precise facts (~200 chars)                         â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Output: ~550 Hierarchical Nodes                                â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚     â†“                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  STAGE 1.4: INDEX LAYER                                         â”‚    â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚    â”‚
â”‚  â”‚  File: RAG/Index_Layer/index_layer.py                           â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Process:                                                        â”‚    â”‚
â”‚  â”‚  1. Initialize embedding model                                  â”‚    â”‚
â”‚  â”‚     â€¢ Model: text-embedding-3-small                             â”‚    â”‚
â”‚  â”‚     â€¢ Dimension: 1536                                           â”‚    â”‚
â”‚  â”‚     â€¢ CRITICAL: Same model for build AND query                  â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  2. Embed all 550 nodes                                         â”‚    â”‚
â”‚  â”‚     â€¢ API call for each node â†’ 1536-dim vector                  â”‚    â”‚
â”‚  â”‚     â€¢ Vectors capture semantic meaning                          â”‚    â”‚
â”‚  â”‚     â€¢ Main time cost: ~5 minutes (API calls)                    â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  3. Build FAISS vector store                                    â”‚    â”‚
â”‚  â”‚     â€¢ Fast similarity search index                              â”‚    â”‚
â”‚  â”‚     â€¢ Stores embeddings + metadata                              â”‚    â”‚
â”‚  â”‚     â€¢ Enables sub-second retrieval                              â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  4. Create storage context                                      â”‚    â”‚
â”‚  â”‚     â€¢ docstore: Original node texts                             â”‚    â”‚
â”‚  â”‚     â€¢ vector_store: Embeddings                                  â”‚    â”‚
â”‚  â”‚     â€¢ index_store: Relationships                                â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  5. Build VectorStoreIndex                                      â”‚    â”‚
â”‚  â”‚     â€¢ Combines vector store + storage                           â”‚    â”‚
â”‚  â”‚     â€¢ Handles query-time search                                 â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  6. Build SummaryIndex                                          â”‚    â”‚
â”‚  â”‚     â€¢ For comprehensive retrieval (no filtering)                â”‚    â”‚
â”‚  â”‚     â€¢ Used by MapReduce                                         â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  7. Create retrievers                                           â”‚    â”‚
â”‚  â”‚     â€¢ Needle Retriever: top_k=3, threshold=0.75                 â”‚    â”‚
â”‚  â”‚       â†’ For atomic questions (high precision)                   â”‚    â”‚
â”‚  â”‚     â€¢ MapReduce Engine: top_k=15                                â”‚    â”‚
â”‚  â”‚       â†’ For complex questions (high recall)                     â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  8. Save to disk                                                â”‚    â”‚
â”‚  â”‚     â€¢ production_index/docstore.json                            â”‚    â”‚
â”‚  â”‚     â€¢ production_index/vector_store.json                        â”‚    â”‚
â”‚  â”‚     â€¢ production_index/index_store.json                         â”‚    â”‚
â”‚  â”‚     â€¢ production_index/default__vector_store.json               â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Output: production_index/ folder                               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚     â†“                                                                     â”‚
â”‚  ğŸ’¾ OUTPUT: production_index/ (ready for query time!)                   â”‚
â”‚                                                                          â”‚
â”‚  âœ… RESULT:                                                              â”‚
â”‚     â€¢ 550 embedded nodes stored in FAISS                                â”‚
â”‚     â€¢ Fast similarity search enabled                                    â”‚
â”‚     â€¢ Ready to answer questions in seconds                              â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **Flow 1 Stage Summary:**

| Stage | File | Input | Output | Duration |
|-------|------|-------|--------|----------|
| 1.1 PDF Ingestion | `pdf_ingestion.py` | PDF file | 1 Document | ~30 sec |
| 1.2 Claim Segmentation | `claim_segmentation.py` | 1 Document | 20 Documents | ~5 sec |
| 1.3 Chunking | `chunking_layer.py` | 20 Documents | 550 Nodes | ~10 sec |
| 1.4 Indexing | `index_layer.py` | 550 Nodes | production_index/ | ~5-10 min |
| **Total** | | **PDF** | **Searchable Index** | **~5-10 min** |

---

## **FLOW 2: Query Time (Answering Questions)**

### **Complete Flow Diagram:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FLOW 2: QUERY TIME                                   â”‚
â”‚                 (Every Question - ~2-5 seconds)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  ğŸ’¬ INPUT: User Question                                                â”‚
â”‚            "What is Jon Mor's phone number?"                             â”‚
â”‚                                                                          â”‚
â”‚     â†“                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  STAGE 2.1: LOAD PRODUCTION INDEX (The out put of Flow 1)                              â”‚    â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚    â”‚
â”‚  â”‚  File: main.py â†’ index_layer.py                                 â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Process:                                                        â”‚    â”‚
â”‚  â”‚  1. Read production_index/ folder from disk                     â”‚    â”‚
â”‚  â”‚  2. Load docstore.json (node texts)                             â”‚    â”‚
â”‚  â”‚  3. Load vector_store.json (embeddings)                         â”‚    â”‚
â”‚  â”‚  4. Load index_store.json (relationships)                       â”‚    â”‚
â”‚  â”‚  5. Reconstruct FAISS index in memory                           â”‚    â”‚
â”‚  â”‚  6. Recreate VectorStoreIndex                                   â”‚    â”‚
â”‚  â”‚  7. Recreate SummaryIndex                                       â”‚    â”‚
â”‚  â”‚  8. Initialize embedding model (SAME as build time)             â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Duration: ~2 seconds (no API calls, just file loading)         â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Output: Index loaded in memory, ready for queries              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚     â†“                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  STAGE 2.2: INITIALIZE AGENTS                                   â”‚    â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚    â”‚
â”‚  â”‚  File: main.py                                                  â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Process:                                                        â”‚    â”‚
â”‚  â”‚  1. Create Router Agent                                         â”‚    â”‚
â”‚  â”‚     â€¢ LLM: gpt-4o-mini, temp=0.0                                â”‚    â”‚
â”‚  â”‚     â€¢ Purpose: Classify question type                           â”‚    â”‚
â”‚  â”‚     â€¢ Output: "needle" or "summary" route                       â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  2. Create Needle Agent                                         â”‚    â”‚
â”‚  â”‚     â€¢ LLM: gpt-4o-mini, temp=0.0                                â”‚    â”‚
â”‚  â”‚     â€¢ Purpose: Extract atomic facts                             â”‚    â”‚
â”‚  â”‚     â€¢ Features: MCP tools enabled, null-safe                    â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  3. Create Summary Agent                                        â”‚    â”‚
â”‚  â”‚     â€¢ LLM: gpt-4o-mini, temp=0.2                                â”‚    â”‚
â”‚  â”‚     â€¢ Purpose: Synthesize comprehensive answers                 â”‚    â”‚
â”‚  â”‚     â€¢ Features: MCP tools enabled, MapReduce support            â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  4. Get retrievers from Index Layer                             â”‚    â”‚
â”‚  â”‚     â€¢ Needle Retriever (top_k=3, threshold=0.75)                â”‚    â”‚
â”‚  â”‚     â€¢ MapReduce Query Engine (top_k=15)                         â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Duration: <1 second (LLM initialization)                       â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Output: Three agents ready, retrievers configured              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚     â†“                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  STAGE 2.3: ORCHESTRATOR INITIALIZATION                         â”‚    â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚    â”‚
â”‚  â”‚  File: main.py â†’ orchestrator.py                                â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Process:                                                        â”‚    â”‚
â”‚  â”‚  1. Inject all dependencies                                     â”‚    â”‚
â”‚  â”‚     â€¢ Router Agent                                              â”‚    â”‚
â”‚  â”‚     â€¢ Needle Agent                                              â”‚    â”‚
â”‚  â”‚     â€¢ Summary Agent                                             â”‚    â”‚
â”‚  â”‚     â€¢ Needle Retriever                                          â”‚    â”‚
â”‚  â”‚     â€¢ MapReduce Engine                                          â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  2. Validate all components present                             â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  3. Create orchestrator instance                                â”‚    â”‚
â”‚  â”‚     â€¢ Pure coordinator (no business logic)                      â”‚    â”‚
â”‚  â”‚     â€¢ Stateless (no memory between queries)                     â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Duration: <1 second                                            â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Output: Orchestrator ready to handle queries                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚     â†“                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  STAGE 2.4: QUERY PREPROCESSING                                 â”‚    â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚    â”‚
â”‚  â”‚  File: orchestrator.py (run method)                             â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Process:                                                        â”‚    â”‚
â”‚  â”‚  1. Analyze user question for claim identifiers                 â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  2. Extract claim number (if present)                           â”‚    â”‚
â”‚  â”‚     â€¢ Patterns: "claim #5", "form number 5"                     â”‚    â”‚
â”‚  â”‚     â€¢ Result: claim_number = "5"                                â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  3. Extract claimant name (if present)                          â”‚    â”‚
â”‚  â”‚     â€¢ Pattern: Capitalized first + last name                    â”‚    â”‚
â”‚  â”‚     â€¢ Example: "Jon Mor's phone" â†’ "Jon Mor"                    â”‚    â”‚
â”‚  â”‚     â€¢ Result: claimant_name = "Jon Mor"                         â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  4. Create PostFilterRetriever (if needed)                      â”‚    â”‚
â”‚  â”‚     â€¢ If claim identifier detected:                             â”‚    â”‚
â”‚  â”‚       â†’ Wrap base retriever                                     â”‚    â”‚
â”‚  â”‚       â†’ Retrieve 3x more results                                â”‚    â”‚
â”‚  â”‚       â†’ Filter by metadata (claim_number OR claimant_name)      â”‚    â”‚
â”‚  â”‚       â†’ Return top_k after filtering                            â”‚    â”‚
â”‚  â”‚     â€¢ Why: FAISS doesn't support native metadata filtering      â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Duration: <100ms                                               â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Output: Filtered or default retriever ready                    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚     â†“                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  STAGE 2.5: ROUTING DECISION                                    â”‚    â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚    â”‚
â”‚  â”‚  File: orchestrator.py â†’ router_agent.py                        â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Process:                                                        â”‚    â”‚
â”‚  â”‚  1. Send question to Router Agent                               â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  2. Router LLM analyzes question intent                         â”‚    â”‚
â”‚  â”‚     â€¢ No retrieval at this stage (pure classification)          â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  3. Classification logic:                                       â”‚    â”‚
â”‚  â”‚     â€¢ NEEDLE: Single specific fact needed                       â”‚    â”‚
â”‚  â”‚       Examples: "What's the phone?", "When accident?"           â”‚    â”‚
â”‚  â”‚       Also: Date calculations ("How many days?")                â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚     â€¢ SUMMARY: Multiple facts or explanation                    â”‚    â”‚
â”‚  â”‚       Examples: "Summarize claim", "What happened?"             â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  4. Return route decision                                       â”‚    â”‚
â”‚  â”‚     â€¢ route: "needle" or "summary"                              â”‚    â”‚
â”‚  â”‚     â€¢ confidence: 0.0 to 1.0                                    â”‚    â”‚
â”‚  â”‚     â€¢ reason: Explanation                                       â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Example for "What is Jon Mor's phone?":                        â”‚    â”‚
â”‚  â”‚     route = "needle"                                            â”‚    â”‚
â”‚  â”‚     confidence = 0.95                                           â”‚    â”‚
â”‚  â”‚     reason = "Asks for single specific fact"                    â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Duration: ~500ms (LLM API call)                                â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Output: Routing decision (which agent to use)                  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚     â†“                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  STAGE 2.6a: NEEDLE AGENT EXECUTION (if route = "needle")       â”‚    â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚    â”‚
â”‚  â”‚  File: orchestrator.py â†’ needle_agent.py                        â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Process:                                                        â”‚    â”‚
â”‚  â”‚  1. RETRIEVAL                                                   â”‚    â”‚
â”‚  â”‚     â€¢ Use Needle Retriever (top_k=3, threshold=0.75)            â”‚    â”‚
â”‚  â”‚     â€¢ Embed user question                                       â”‚    â”‚
â”‚  â”‚     â€¢ Cosine similarity search in FAISS                         â”‚    â”‚
â”‚  â”‚     â€¢ Return 3 most similar chunks (if above threshold)         â”‚    â”‚
â”‚  â”‚     â€¢ Chunks are ~200 chars (child chunks)                      â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  2. CONTEXT PREPARATION                                         â”‚    â”‚
â”‚  â”‚     â€¢ Format chunks for LLM                                     â”‚    â”‚
â”‚  â”‚     â€¢ Include metadata (claim_id, claimant_name)                â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  3a. STANDARD PATH (No date calculation)                        â”‚    â”‚
â”‚  â”‚      â€¢ Send question + chunks to Needle LLM                     â”‚    â”‚
â”‚  â”‚      â€¢ LLM extracts exact answer                                â”‚    â”‚
â”‚  â”‚      â€¢ Returns structured response                              â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  3b. MCP TOOL PATH (Date calculation needed)                    â”‚    â”‚
â”‚  â”‚      â€¢ LLM recognizes date calculation in question              â”‚    â”‚
â”‚  â”‚      â€¢ Extracts dates from chunks                               â”‚    â”‚
â”‚  â”‚      â€¢ Tool Call Decision (tool_choice="auto"):                 â”‚    â”‚
â”‚  â”‚        â†’ LLM: "I see two dates, call calculate_days_between"    â”‚    â”‚
â”‚  â”‚      â€¢ Tool Execution:                                          â”‚    â”‚
â”‚  â”‚        â†’ calculate_days_between("2024-01-24", "2024-02-18")     â”‚    â”‚
â”‚  â”‚        â†’ Python datetime performs exact calculation             â”‚    â”‚
â”‚  â”‚        â†’ Returns: {"success": True, "number_of_days": 25}       â”‚    â”‚
â”‚  â”‚      â€¢ Final Answer Formation:                                  â”‚    â”‚
â”‚  â”‚        â†’ LLM receives tool result                               â”‚    â”‚
â”‚  â”‚        â†’ Formats: "25 days passed between..."                   â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  4. RESPONSE FORMATION                                          â”‚    â”‚
â”‚  â”‚     â€¢ answer: Extracted fact or "null"                          â”‚    â”‚
â”‚  â”‚     â€¢ confidence: 1.0 if found, 0.0 if not                      â”‚    â”‚
â”‚  â”‚     â€¢ sources: List of chunk IDs                                â”‚    â”‚
â”‚  â”‚     â€¢ reason: Explanation (mentions MCP if used)                â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Example Response:                                              â”‚    â”‚
â”‚  â”‚     answer = "555-1234"                                         â”‚    â”‚
â”‚  â”‚     confidence = 1.0                                            â”‚    â”‚
â”‚  â”‚     sources = ["chunk_abc123"]                                  â”‚    â”‚
â”‚  â”‚     reason = "Found in contact section"                         â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Duration: ~1-2 seconds (retrieval + LLM)                       â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Output: Precise answer with high confidence                    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚     â”‚                                                                    â”‚
â”‚     OR                                                                   â”‚
â”‚     â”‚                                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  STAGE 2.6b: SUMMARY AGENT EXECUTION (if route = "summary")     â”‚    â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚    â”‚
â”‚  â”‚  File: orchestrator.py â†’ summary_agent.py                       â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Process (MapReduce Approach):                                  â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  1. RETRIEVAL PHASE                                             â”‚    â”‚
â”‚  â”‚     â€¢ Use MapReduce Query Engine                                â”‚    â”‚
â”‚  â”‚     â€¢ Retrieve top_k=15 chunks (comprehensive)                  â”‚    â”‚
â”‚  â”‚     â€¢ Uses both parent and child chunks                         â”‚    â”‚
â”‚  â”‚     â€¢ No similarity threshold (high recall)                     â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  2. MAP PHASE                                                   â”‚    â”‚
â”‚  â”‚     â€¢ For each of 15 retrieved chunks:                          â”‚    â”‚
â”‚  â”‚       â†’ LLM generates summary of that chunk                     â”‚    â”‚
â”‚  â”‚       â†’ Focuses on question-relevant information                â”‚    â”‚
â”‚  â”‚     â€¢ Results in 15 mini-summaries                              â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  3. REDUCE PHASE                                                â”‚    â”‚
â”‚  â”‚     â€¢ LLM combines all mini-summaries                           â”‚    â”‚
â”‚  â”‚     â€¢ Synthesizes coherent final answer                         â”‚    â”‚
â”‚  â”‚     â€¢ Resolves contradictions                                   â”‚    â”‚
â”‚  â”‚     â€¢ Organizes information logically                           â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  4. MCP TOOL INTEGRATION (if needed)                            â”‚    â”‚
â”‚  â”‚     â€¢ During synthesis, LLM may recognize date calculation      â”‚    â”‚
â”‚  â”‚     â€¢ Calls calculate_days_between with dates from context      â”‚    â”‚
â”‚  â”‚     â€¢ Incorporates exact calculation in final answer            â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  5. RESPONSE FORMATION                                          â”‚    â”‚
â”‚  â”‚     â€¢ answer: Comprehensive synthesized response                â”‚    â”‚
â”‚  â”‚     â€¢ confidence: 0.8-0.9 (synthesis less certain)              â”‚    â”‚
â”‚  â”‚     â€¢ sources: All chunk IDs used (15+)                         â”‚    â”‚
â”‚  â”‚     â€¢ reason: Explanation of synthesis                          â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Example Response:                                              â”‚    â”‚
â”‚  â”‚     answer = "Jon Mor filed a claim on Jan 26, 2024,            â”‚    â”‚
â”‚  â”‚               following an accident on Jan 24, 2024..."         â”‚    â”‚
â”‚  â”‚     confidence = 0.9                                            â”‚    â”‚
â”‚  â”‚     sources = [15+ chunk IDs]                                   â”‚    â”‚
â”‚  â”‚     reason = "Synthesized from incident and payment sections"   â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Duration: ~2-4 seconds (retrieval + multiple LLM calls)        â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Output: Comprehensive answer with broad context                â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚     â†“                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  STAGE 2.7: RESPONSE NORMALIZATION                              â”‚    â”‚
â”‚  â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚    â”‚
â”‚  â”‚  File: orchestrator.py (run method)                             â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Process:                                                        â”‚    â”‚
â”‚  â”‚  1. Combine routing metadata + agent result                     â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  2. Create unified response structure:                          â”‚    â”‚
â”‚  â”‚     {                                                            â”‚    â”‚
â”‚  â”‚       "route": "needle" or "summary",                           â”‚    â”‚
â”‚  â”‚       "answer": "555-1234",                                     â”‚    â”‚
â”‚  â”‚       "confidence": 1.0,                                        â”‚    â”‚
â”‚  â”‚       "sources": ["chunk_abc123", ...],                         â”‚    â”‚
â”‚  â”‚       "retrieved_chunks_content": ["Phone: 555-1234", ...],     â”‚    â”‚
â”‚  â”‚       "reason": "Found in contact section"                      â”‚    â”‚
â”‚  â”‚     }                                                            â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  3. Log results:                                                â”‚    â”‚
â”‚  â”‚     â€¢ Print route decision                                      â”‚    â”‚
â”‚  â”‚     â€¢ Print final answer                                        â”‚    â”‚
â”‚  â”‚     â€¢ Print confidence score                                    â”‚    â”‚
â”‚  â”‚     â€¢ Print number of sources                                   â”‚    â”‚
â”‚  â”‚     â€¢ Print reasoning                                           â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Duration: <100ms                                               â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  Output: Standardized response for external consumers           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚     â†“                                                                     â”‚
â”‚  âœ… OUTPUT: Final Answer                                                â”‚
â”‚            "555-1234"                                                    â”‚
â”‚                                                                          â”‚
â”‚  ğŸ“Š TOTAL TIME: ~2-5 seconds (fast!)                                    â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **Flow 2 Stage Summary:**

| Stage | File | Purpose | Duration |
|-------|------|---------|----------|
| 2.1 Load Index | `index_layer.py` | Load pre-built index from disk | ~2 sec |
| 2.2 Initialize Agents | `main.py` | Create Router, Needle, Summary agents | <1 sec |
| 2.3 Orchestrator Init | `orchestrator.py` | Create central coordinator | <1 sec |
| 2.4 Query Preprocessing | `orchestrator.py` | Extract claim identifiers, create filters | <100ms |
| 2.5 Routing | `router_agent.py` | Classify question (needle/summary) | ~500ms |
| 2.6a Needle Execution | `needle_agent.py` | Extract atomic fact (+ MCP if needed) | ~1-2 sec |
| 2.6b Summary Execution | `summary_agent.py` | Synthesize comprehensive answer (MapReduce) | ~2-4 sec |
| 2.7 Response Normalization | `orchestrator.py` | Format unified response | <100ms |
| **Total** | | **Question â†’ Answer** | **~2-5 sec** |

---

### **Flow 2 Decision Tree:**

```
User Question
    â†“
Load Index â†’ Initialize Agents â†’ Orchestrator
    â†“
Query Preprocessing
    â”œâ”€ Claim Number? â†’ Filter by claim_number
    â”œâ”€ Claimant Name? â†’ Filter by claimant_name
    â””â”€ No identifier â†’ Use default retriever
    â†“
Routing Decision
    â”œâ”€ Route = NEEDLE
    â”‚   â†“
    â”‚   Needle Agent
    â”‚   â”œâ”€ Retrieve 3 chunks (threshold=0.75)
    â”‚   â”œâ”€ Date calculation needed?
    â”‚   â”‚   â”œâ”€ YES â†’ Call MCP tool â†’ Format answer
    â”‚   â”‚   â””â”€ NO â†’ Extract fact â†’ Return answer
    â”‚   â””â”€ Return precise answer
    â”‚
    â””â”€ Route = SUMMARY
        â†“
        Summary Agent
        â”œâ”€ Retrieve 15 chunks (no threshold)
        â”œâ”€ Map Phase: Summarize each chunk
        â”œâ”€ Reduce Phase: Combine summaries
        â”œâ”€ Date calculation needed?
        â”‚   â”œâ”€ YES â†’ Call MCP tool â†’ Incorporate in answer
        â”‚   â””â”€ NO â†’ Return synthesized answer
        â””â”€ Return comprehensive answer
    â†“
Response Normalization
    â†“
Final Answer to User
```

---

### **Key Differences Between Flows:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FLOW 1 vs. FLOW 2 COMPARISON                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  FLOW 1 (Build Index):                                  â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”   â”‚
â”‚  â€¢ When: Once (or when data changes)                    â”‚
â”‚  â€¢ Duration: 5-10 minutes                               â”‚
â”‚  â€¢ Main Cost: Embedding API calls (550 chunks)          â”‚
â”‚  â€¢ Output: production_index/ folder on disk             â”‚
â”‚  â€¢ Purpose: Prepare data for fast retrieval             â”‚
â”‚  â€¢ Stages: 4 (Ingest â†’ Segment â†’ Chunk â†’ Index)        â”‚
â”‚                                                         â”‚
â”‚                                                         â”‚
â”‚  FLOW 2 (Query Time):                                   â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”   â”‚
â”‚  â€¢ When: Every user question                            â”‚
â”‚  â€¢ Duration: 2-5 seconds                                â”‚
â”‚  â€¢ Main Cost: LLM API calls (1-3 per query)             â”‚
â”‚  â€¢ Output: Natural language answer                      â”‚
â”‚  â€¢ Purpose: Answer questions fast                       â”‚
â”‚  â€¢ Stages: 7 (Load â†’ Init â†’ Route â†’ Execute â†’ Answer)  â”‚
â”‚                                                         â”‚
â”‚                                                         â”‚
â”‚  WHY THIS DESIGN:                                       â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”   â”‚
â”‚  âœ… Efficiency: Build once, query many times            â”‚
â”‚  âœ… Speed: Query time is fast (no re-embedding)         â”‚
â”‚  âœ… Cost: Embedding cost paid once, not per query       â”‚
â”‚  âœ… Scalability: Supports concurrent users              â”‚
â”‚  âœ… Production-Ready: Proven architecture pattern       â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

This system is built in **5 strict layers**:

### Layer 1: PDF Ingestion âœ… COMPLETE
- **Input**: PDF file
- **Output**: Clean LlamaIndex Document with metadata
- **Status**: Implemented and tested
- **Location**: `RAG/PDF_Ingestion/`

### Layer 2: Chunking âœ… COMPLETE
- **Input**: LlamaIndex Document
- **Output**: Hierarchical Nodes (Sections â†’ Parent â†’ Child)
- **Status**: Implemented and tested
- **Location**: `RAG/Chunking_Layer/`

### Layer 3: Index
- **Input**: Hierarchical Nodes
- **Output**: VectorStoreIndex + SummaryIndex + AutoMergingRetriever
- **Status**: Not yet implemented

### Layer 4: Agents
- **Input**: Indexes and Retrievers
- **Output**: Router Agent, Needle Agent, Summary Agent
- **Status**: Not yet implemented

### Layer 5: Orchestration
- **Input**: All agents
- **Output**: Complete RAG pipeline
- **Status**: Not yet implemented

## Technology Stack

- **RAG Core**: LlamaIndex (documents, nodes, chunking, indexes, retrieval)
- **Agents & Orchestration**: LangChain (LCEL, Runnables, Chains)
- **Vector Store**: FAISS
- **Embeddings**: OpenAI Embeddings (via LlamaIndex)
- **LLM**: OpenAI GPT models

## Setup

### 1. Create Virtual Environment (conda)

```bash
conda create -n ragagent python=3.11 -y
conda activate ragagent
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Configure Environment

Create a `.env` file in the project root:

```
OPENAI_API_KEY=your_openai_api_key_here
```


## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER INTERFACE                            â”‚
â”‚                   (Query Input / Answer Output)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
        â•‘         ORCHESTRATOR LAYER             â•‘
        â•‘   (RAG/Orchestration/orchestrator.py)  â•‘
        â•‘                                        â•‘
        â•‘  â€¢ Entry point for all queries         â•‘
        â•‘  â€¢ Coordinates agent workflow          â•‘
        â•‘  â€¢ Formats final response              â•‘
        â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                               â”‚
         â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ROUTER AGENT   â”‚            â”‚  AGENTS LAYER   â”‚
â”‚                 â”‚            â”‚                 â”‚
â”‚  â€¢ Query        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  â€¢ Needle Agent â”‚
â”‚    Classificationâ”‚            â”‚  â€¢ Summary Agentâ”‚
â”‚  â€¢ Route         â”‚            â”‚                 â”‚
â”‚    Decision      â”‚            â”‚  Request        â”‚
â”‚                 â”‚            â”‚  Retrieval      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
                        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
                        â•‘      INDEX LAYER â­          â•‘
                        â•‘  (Retrieval Engine)          â•‘
                        â•‘                              â•‘
                        â•‘  1. Embed Query              â•‘
                        â•‘  2. Vector Search            â•‘
                        â•‘  3. Apply Filters            â•‘
                        â•‘  4. Return Chunks            â•‘
                        â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                        â”‚
                                        â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   VECTOR DATABASE             â”‚
                        â”‚   â€¢ All document chunks       â”‚
                        â”‚   â€¢ Pre-computed embeddings   â”‚
                        â”‚   â€¢ Metadata & filters        â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Complete Query Flow

### Visual Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER QUERY                            â”‚
â”‚              "What is Jon Mor's phone number?"               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   STEP 1: ORCHESTRATOR (Entry)        â”‚
        â”‚   RAG/Orchestration/orchestrator.py   â”‚
        â”‚                                        â”‚
        â”‚   â€¢ Receives user query                â”‚
        â”‚   â€¢ Initializes processing             â”‚
        â”‚   â€¢ Sends to Router Agent              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   STEP 2: ROUTER AGENT (Classify)     â”‚
        â”‚   RAG/Agents/router_agent.py          â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚ ğŸ¤– LLM: gpt-4o-mini            â”‚  â”‚
        â”‚  â”‚ Analyzes: Query type?           â”‚  â”‚
        â”‚  â”‚ Decision: "NEEDLE"              â”‚  â”‚
        â”‚  â”‚ Reason: Specific fact needed    â”‚  â”‚
        â”‚  â”‚ Confidence: 1.0                 â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   STEP 3: NEEDLE AGENT (Handle)       â”‚
        â”‚   RAG/Agents/needle_agent.py          â”‚
        â”‚                                        â”‚
        â”‚   â€¢ Receives NEEDLE route              â”‚
        â”‚   â€¢ Prepares retrieval request         â”‚
        â”‚   â€¢ Calls needle_retriever             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          STEP 4: INDEX LAYER (Retrieval) â­                    â”‚
â”‚          RAG/Index_Layer/index_layer.py                        â”‚
â”‚                                                                 â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“   â”‚
â”‚  â”ƒ STEP 4A: EMBED QUERY                                  â”ƒ   â”‚
â”‚  â”ƒ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”ƒ   â”‚
â”‚  â”ƒ â”‚ Embedding Model: text-embedding-3-small       â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚ Input (Text):                                 â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚   "What is Jon Mor's phone number?"           â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚ Output (Vector - 1536 dimensions):            â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚   [0.234, -0.456, 0.678, 0.123, -0.891, ...] â”‚   â”ƒ   â”‚
â”‚  â”ƒ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”ƒ   â”‚
â”‚  â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›   â”‚
â”‚                              â”‚                                  â”‚
â”‚                              â–¼                                  â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“   â”‚
â”‚  â”ƒ STEP 4B: VECTOR SEARCH (Calculate Similarities)      â”ƒ   â”‚
â”‚  â”ƒ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”ƒ   â”‚
â”‚  â”ƒ â”‚ Compare query vector with ALL chunks in DB     â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚ Cosine Similarity Calculation:                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚ Query: [0.234, -0.456, 0.678, ...]            â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚ Chunk 1 [0.231, -0.451, 0.682, ...] â†’ 0.95 âœ…â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚   "Jon Mor, Phone: (555) 100-2000"            â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚ Chunk 2 [0.198, -0.423, 0.701, ...] â†’ 0.82 âœ…â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚   "Contact Info: Jon Mor..."                  â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚ Chunk 3 [0.241, -0.389, 0.655, ...] â†’ 0.78 âœ…â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚   "Claimant: Jon Mor, Account..."             â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚ Chunk 4 [0.112, -0.298, 0.544, ...] â†’ 0.68   â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚   "Jon Mor vehicle: Toyota..."                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚ Chunk 5 [0.034, 0.123, -0.234, ...] â†’ 0.45   â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚   "Eli Cohen claim details..."                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚ ... (all other chunks ranked)                 â”‚   â”ƒ   â”‚
â”‚  â”ƒ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”ƒ   â”‚
â”‚  â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›   â”‚
â”‚                              â”‚                                  â”‚
â”‚                              â–¼                                  â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“   â”‚
â”‚  â”ƒ STEP 4C: APPLY FILTERS âš™ï¸                            â”ƒ   â”‚
â”‚  â”ƒ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”ƒ   â”‚
â”‚  â”ƒ â”‚ âš™ï¸ Settings:                                  â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚   â€¢ similarity_threshold = 0.75               â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚   â€¢ top_k = 3                                 â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚ ğŸ” Filter Step 1: similarity_threshold        â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚    (Keep only chunks with score â‰¥ 0.75)      â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚    â”œâ”€ Chunk 1: 0.95 â‰¥ 0.75 âœ… KEEP           â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚    â”œâ”€ Chunk 2: 0.82 â‰¥ 0.75 âœ… KEEP           â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚    â”œâ”€ Chunk 3: 0.78 â‰¥ 0.75 âœ… KEEP           â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚    â”œâ”€ Chunk 4: 0.68 < 0.75 âŒ FILTERED OUT   â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚    â””â”€ Chunk 5: 0.45 < 0.75 âŒ FILTERED OUT   â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚    Remaining: 3 chunks pass threshold         â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚ ğŸ” Filter Step 2: top_k                       â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚    (Take top 3 highest-scoring chunks)        â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚    Result: 3 chunks (all 3 qualify)           â”‚   â”ƒ   â”‚
â”‚  â”ƒ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”ƒ   â”‚
â”‚  â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›   â”‚
â”‚                              â”‚                                  â”‚
â”‚                              â–¼                                  â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“   â”‚
â”‚  â”ƒ STEP 4D: RETURN CHUNK TEXTS                           â”ƒ   â”‚
â”‚  â”ƒ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”ƒ   â”‚
â”‚  â”ƒ â”‚ ğŸ“¦ Final Retrieved Chunks:                    â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚ 1ï¸âƒ£ Chunk 1 (score: 0.95):                    â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚    "Jon Mor, Phone: (555) 100-2000,           â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚     Email: jon.mor@email.com..."              â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚ 2ï¸âƒ£ Chunk 2 (score: 0.82):                    â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚    "Contact Information for Jon Mor:          â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚     Primary phone, secondary contact..."      â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚                                                â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚ 3ï¸âƒ£ Chunk 3 (score: 0.78):                    â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚    "Claimant: Jon Mor, Account: ACC9900460,   â”‚   â”ƒ   â”‚
â”‚  â”ƒ â”‚     Contact details on file..."               â”‚   â”ƒ   â”‚
â”‚  â”ƒ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”ƒ   â”‚
â”‚  â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   STEP 5: NEEDLE AGENT (Extract)      â”‚
        â”‚   RAG/Agents/needle_agent.py          â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚ ğŸ¤– LLM: gpt-4o-mini            â”‚  â”‚
        â”‚  â”‚                                 â”‚  â”‚
        â”‚  â”‚ Prompt:                         â”‚  â”‚
        â”‚  â”‚ "Given these chunks, extract    â”‚  â”‚
        â”‚  â”‚  Jon Mor's phone number.        â”‚  â”‚
        â”‚  â”‚                                 â”‚  â”‚
        â”‚  â”‚  If not found, return None."    â”‚  â”‚
        â”‚  â”‚                                 â”‚  â”‚
        â”‚  â”‚ LLM reads 3 chunks...           â”‚  â”‚
        â”‚  â”‚ LLM finds phone in Chunk 1      â”‚  â”‚
        â”‚  â”‚ LLM extracts: "(555) 100-2000"  â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   STEP 6: ORCHESTRATOR (Format)       â”‚
        â”‚   RAG/Orchestration/orchestrator.py   â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚ Format response:                â”‚  â”‚
        â”‚  â”‚ {                               â”‚  â”‚
        â”‚  â”‚   "answer": "(555) 100-2000",   â”‚  â”‚
        â”‚  â”‚   "route": "NEEDLE",            â”‚  â”‚
        â”‚  â”‚   "confidence": 0.95,           â”‚  â”‚
        â”‚  â”‚   "sources": ["chunk_1"],       â”‚  â”‚
        â”‚  â”‚   "retrieved_chunks": [...]     â”‚  â”‚
        â”‚  â”‚ }                               â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    FINAL ANSWER       â”‚
            â”‚                       â”‚
            â”‚  "(555) 100-2000"     â”‚
            â”‚                       â”‚
            â”‚  Delivered to user âœ… â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---
## Design Principles

### Strict Layer Separation
- Each layer has ONE responsibility
- No cross-layer contamination
- Clear input/output contracts

### Embedding Consistency
- Embeddings defined ONCE during index construction
- Reused implicitly via StorageContext
- Never instantiated at query time

### Production Quality
- Heavy inline documentation explaining WHY
- Comprehensive error handling
- Deterministic behavior
- Extensive testing

### No Shortcuts
- No premature optimization
- No mixing of responsibilities
- No simplifications that break the architecture

## Development

### Adding a New Layer

1. Create folder: `RAG/LayerName/`
2. Create `__init__.py` with exports
3. Create main module: `layer_name.py`
4. Create test notebook: `test_layer_name.ipynb`
5. Document inputs, outputs, and responsibilities
6. Test in isolation before integrating

### Testing

Each layer includes a Jupyter notebook for human inspection:
- Validates layer functionality
- Inspects intermediate outputs
- Provides debugging visibility
- Documents expected behavior

## Current Status

- âœ… **Layer 1 (PDF Ingestion)**: Complete and tested
- âœ… **Layer 2 (Claim Segmentation)**: Complete - handles multi-claim PDFs (20 claims)
- âœ… **Layer 3 (Chunking)**: Complete - hierarchical nodes with claim metadata
- âœ… **Layer 4 (Index)**: Complete - FAISS vector store + SummaryIndex
- âœ… **Layer 5 (Agents)**: Complete - Router, Needle, Summary agents
- âœ… **Layer 6 (Orchestration)**: Complete - Full pipeline with metadata filtering
- âœ… **Production Index**: Fast query system with pre-built indexes
- âœ… **Metadata Filtering**: Smart claim-specific queries (e.g., "claim number 5")

## License

Internal project - Not for distribution
